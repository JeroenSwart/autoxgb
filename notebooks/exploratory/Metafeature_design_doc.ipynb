{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design document for initial metafeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build raw dataset extractor\n",
    "\n",
    "2. Pluis uit metafeatures:\n",
    "- dataset length\n",
    "- max(variance)/min(variance)\n",
    "- PSR test\n",
    "- Wavelet spectrum test\n",
    "- Cumulative autocorrelation\n",
    "\n",
    "perform these tasks\n",
    "- describe hypothesized hyperparameter correlation\n",
    "- gather info and summarize the metafeature\n",
    "- find library to implement\n",
    "\n",
    "3. The following step is making a metafeature implemenation plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pluis uit metafeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.metalearning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c0bedbcfa95c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetalearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetaSample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetaDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# get an example series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.metalearning'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from src.metalearning.metadata import MetaSample, MetaDataset\n",
    "\n",
    "# get an example series\n",
    "pickle_in = open('../../data/metadata/interim/COAST_box_8760',\"rb\")\n",
    "time_series = pickle.load(pickle_in).time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter correlation:\n",
    "When the dataset is longer, it is expected that num_trees will become bigger, since you can capture more detailed info when there are more details (more data). More available untill convergence, means that we can also take it slower learning --> lower learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max(variance)/min(variance)\n",
    "Hyperparameter correlation: if the dataset's variance fluctuates highly, that means the underlying signal is time variant in a way that the model does not capture. Hyperparameters should be guarding against overfitting.\n",
    "It should be calculating by getting a rolling variance, with a window of let's say 10 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.722227768281313"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxminvar(time_series):\n",
    "    rolling_var = a.time_series['endogenous'].rolling(24*10).var()\n",
    "    maxminvar = rolling_var.max()/rolling_var.min()\n",
    "    return maxminvar\n",
    "\n",
    "maxminvar(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSR test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Collecting statsmodels\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/bf/4fab954764a786921c64f84051cc2e7c2635fd1669dfdfb3489aaf2bad5f/statsmodels-0.10.1-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (10.6MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6MB 589kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.11 (from statsmodels)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/67/8907005262f493e356195bcbd61b41988eecf63cb1d97ea2f6e55fe24205/numpy-1.16.5-cp27-cp27m-macosx_10_9_x86_64.whl (13.9MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9MB 15.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=0.19 (from statsmodels)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/ff/912fe03a623a70bcf297d466013a0b4f4c68c3b60f86bf226682d061fc09/pandas-0.24.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (16.7MB)\n",
      "\u001b[K     |████████████████████████████████| 16.7MB 64kB/s s eta 0:00:017.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting patsy>=0.4.0 (from statsmodels)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/0c/5f61f1a3d4385d6bf83b83ea495068857ff8dfb89e74824c6e9eb63286d8/patsy-0.5.1-py2.py3-none-any.whl (231kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.18 (from statsmodels)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/cf/36b77de4ccb1b841acd4c3c03abe38843c63c3a657cedee9e8fb19a02dc8/scipy-1.2.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (27.4MB)\n",
      "\u001b[K     |████████████████████████████████| 27.4MB 209kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil>=2.5.0 (from pandas>=0.19->statsmodels)\n",
      "  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2011k in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from pandas>=0.19->statsmodels) (2013.7)\n",
      "Requirement already satisfied: six in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from patsy>=0.4.0->statsmodels) (1.4.1)\n",
      "\u001b[31mERROR: python-dateutil 2.8.0 has requirement six>=1.5, but you'll have six 1.4.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, python-dateutil, pandas, patsy, scipy, statsmodels\n",
      "  Found existing installation: numpy 1.8.0rc1\n",
      "\u001b[31mERROR: Cannot uninstall 'numpy'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d4886f145d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstattools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madfuller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'daily-total-female-births.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madfuller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ADF Statistic: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "series = read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "X = series.values\n",
    "result = adfuller(X)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet spectrum test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative autocorrelation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoXGB Notebook",
   "language": "python",
   "name": "autoxgb_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
